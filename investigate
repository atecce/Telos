#!/usr/bin/env python
#
# I should not like my writing to spare other people the trouble of thinking. 
# But, if possible, to stimulate someone to thoughts of their own.
#

# need this for inspiration
from inspiration.song import song

# need these to get and parse html
from bs4 import BeautifulSoup
import requests
import re

# set up main page
root_url  = 'http://www.lyrics.net/'
main_page = requests.get(root_url)
main_soup = BeautifulSoup(main_page.content, 'lxml')

# keep these to skip collected urls
subalphabet_suburls = list()
artist_urls 	    = list()

# crawl the main page
for link in main_soup.find_all('a'):

	# filter out unwanted links
	if '.php' in link.get('href'): continue 
	if 'http' in link.get('href'): continue

	# the rest are alphabet suburls
	alphabet_suburl = link.get('href')

	# only get links relevant to artists
	if 'artists' in alphabet_suburl:

		# set up alphabet page
		alphabet_url  = root_url + alphabet_suburl
		alphabet_page = requests.get(alphabet_url)
		alphabet_soup = BeautifulSoup(alphabet_page.content, 'lxml')

		print
		print alphabet_url
		print

		# crawl the alphabet page
		for alphabet_link in alphabet_soup.find_all('a'):

			# filter out links without 'artists' in them
			if 'artists' in alphabet_link.get('href'):
			
				# the rest are subalphabet links
				subalphabet_suburl = alphabet_link.get('href')

				# skip links already accumulated
				if subalphabet_suburl in subalphabet_suburls: continue

				# accumulate links
				subalphabet_suburls.append(subalphabet_suburl)

				print
				print '\t', subalphabet_suburl
				print

				# set up subalphabet page	
				subalphabet_page = requests.get(root_url + subalphabet_suburl)
				subalphabet_soup = BeautifulSoup(subalphabet_page.content, 'lxml')

				# crawl the subalphabet page
				for subalphabet_link in subalphabet_soup.find_all('a'):

					# filter out unwanted links
					if re.match(r'^/.*', subalphabet_link.get('href')): continue

					if 'http' 	in subalphabet_link.get('href'): continue 
					if '.php' 	in subalphabet_link.get('href'): continue
					if 'javascript' in subalphabet_link.get('href'): continue

					if root_url + subalphabet_link.get('href') == root_url: continue

					# remaining results are artist urls
					artist_url = root_url + subalphabet_link.get('href')

					# skip links already accumulated
					if artist_url in artist_urls: continue

					# set artist name
					artist_name = re.match(r'.*/(.*)/.*', artist_url).group(1)
					print '\t\t', artist_name
					print

					# accumulate links
					artist_urls.append(artist_url)

					# get up artist page page
					artist_page = requests.get(artist_url)
					artist_soup = BeautifulSoup(artist_page.content, 'lxml')

					# crawl the artist page
					for item in artist_soup.find_all('strong'):

						# get all the links
						links = item.find_all('a')

						# make sure there are more than zero
						if links:

							# set the song title
							song_title = item.find_all('a')[0].text.encode('ascii', 'ignore')

							# set the song url
							song_url = root_url + item.find_all('a')[0].get('href')

							# create the song
							new = song(artist_name, song_title, song_url)
