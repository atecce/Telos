#!/usr/bin/env python
#
# I should not like my writing to spare other people the trouble of thinking.
# But, if possible, to stimulate someone to thoughts of their own.
#

import sys
from time import sleep
import argparse
import re
import string
import requests
from requests.compat import urljoin
from bs4 import BeautifulSoup
from multiprocessing import Process
from db import canvas

class lyrics_site:	

    # keep track of everything
    processes = list()

    siblings = {"artists": list(),
                "albums":  list(),
                "songs":   list()}

    def communicate(self, url):

        # never stop trying
        while True:

            # make some soup
            try:

                page = requests.get(url)

                # handle status codes
                if   page.status_code == 404: sys.exit()    # link not found
                elif page.status_code == 408: continue	    # request timeout
                elif page.status_code == 503: continue	    # server unavailable
                elif page.status_code == 504: continue	    # timeout

                soup = BeautifulSoup(page.content)

                return soup

            # give communication a chance
            except requests.exceptions.ConnectionError: pass

            sleep(1)

    def multitask(self, level, function, process_name, process_args):

        # fork the process
        process = Process(target=function, name=process_name, args=process_args)
        process.start()

        # track the processes
        self.processes.append(process)
        self.siblings[level].append(process)

        # pace yourself
        while len(self.siblings[level]) >= 10: 

            # print "Pruning", level, "..."
            self.siblings[level].pop(0).join()

class lyrics_net(lyrics_site): 

    # know where you are
    url = 'http://www.lyrics.net/'

    canvas = canvas("lyrics_net")

    def investigate(self, start):

        # get the soup
        soup = self.communicate(self.url)

        # set artist expression
        expression = str()

        if start == '0': expression = '^/artists/[0A-Z]$'

        elif start[0] in string.ascii_uppercase:

            expression = '^/artists/[' + start[0] + '-Z]$'

        # extract alphabet urls
        alphabet_urls = (urljoin(self.url, re.match(expression, link.get('href')).group(0) + '/99999') \
                         for link in soup.find_all('div', {'id': 'page-letter-search'})[0]             \
                                  if re.match(expression, str(link.get('href'))))

        # extract artist tags
        artist_tags = (trace.strong.a 		  		     		  \
                       for alphabet_url in alphabet_urls 	     	 	  \
                       for trace in self.communicate(alphabet_url).find_all('tr') \
                                 if trace.strong)

        # get artist data
        artist_data = ((artist_tag.text, urljoin(self.url, artist_tag.get('href'))) for artist_tag in artist_tags)

        # pick up where you left off
        caught_up = bool()

        # for each artist
        for artist_name, artist_url in artist_data: 

            # check if you've caught up
            if re.match("^" + self.url + "artist/" + start + ".*/[0-9]*$", artist_url): caught_up = True

            # if you haven't, continue
            if not caught_up: continue

            # fork
            self.multitask('artists', self.honor, artist_name, (artist_name, artist_url,))

    def honor(self, artist_name, artist_url):

        # get the soup
        artist_soup = self.communicate(artist_url)

        # add the artist to the canvas
        self.canvas.add_artist(artist_name)

        # get the album items
        album_items = artist_soup.find_all('div', {'class': 'clearfix'})

        # for each item
        for item in album_items: 

            # check for a header
            if item.h3:

                # check the header contains a link
                if item.h3.a:

                    # set the album information
                    album_title = item.h3.a.text
                    album_url   = urljoin(self.url, item.h3.a.get('href'))

                    # add the album to the canvas
                    self.canvas.add_album(artist_name, album_title)

                    # get the soup
                    album_soup = self.communicate(album_url)

                    # handle Dorothy (which do not return the proper status code)
                    if album_soup.find_all('body', {'id': 's4-page-homepage'}): 

                        # extract the song data
                        song_data = ((trace.a.text, urljoin(self.url, trace.a.get('href'))) \
                                      for trace in item.find_all('tr') 	   		    \
                                                if trace.a)

                    # otherwise
                    else:

                        # extract the song data
                        song_data = ((song_tag.a.text, urljoin(self.url, song_tag.a.get('href'))) \
                                      for song_tag in album_soup.find_all('strong') 	   	  \
                                                   if song_tag.a)

                    # for each song
                    for song_title, song_url in song_data:

                        # fork
                        self.multitask('songs', self.meditate, song_title, (album_title, song_title, song_url,))

    def meditate(self, album_title, song_title, song_url):

        # make some soup
        song_soup = self.communicate(song_url)

        # sometimes there's nothing to meditate on
        try: lyrics = song_soup.find_all('pre', {'id': 'lyric-body-text'})[0].text

        except IndexError: return

        # add song to canvas
        self.canvas.add_song(album_title, song_title, lyrics)

if __name__ == '__main__':

    # parse arguments
    parser = argparse.ArgumentParser()
    start  = parser.add_argument("-s", "--start", help="specify the start character",
                                                  default='0')
    args   = parser.parse_args()

    # start the investigation
    investigation = lyrics_net()
    investigation.investigate(args.start)
