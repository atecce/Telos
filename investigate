#!/usr/bin/env python
#
# I should not like my writing to spare other people the trouble of thinking.
# But, if possible, to stimulate someone to thoughts of their own.
#

# don't wait for your neighbors
from multiprocessing import Process

# but be patient
import time

class lyrics_site:	

	# set the canvas
	from databases import database
	canvas = database.canvas()

	def communicate(self, url):

		from bs4 import BeautifulSoup
		import requests

		# never stop trying
		while True:

			# make some soup
			try:

				page = requests.get(url)
				soup = BeautifulSoup(page.content)

				return soup

			# give communication a chance
			except requests.exceptions.ConnectionError: pass

			time.sleep(1)

	def multitask(self, level, function, process_name, process_args):

		# fork the process
		process = Process(target=function, name=process_name, args=process_args)
		process.start()

		# track the processes
		self.processes.append(process)
		self.siblings[level].append(process)

		# pace yourself
		while len(self.siblings[level]) >= 8: 
			
			print "Pruning", level
			print len(self.siblings[level])
			print len(self.processes)
			print
			self.siblings[level].pop(0).join()

class lyrics_net(lyrics_site): 

	# keep track of everything
	processes = list()

	siblings = {"artists": list(),
		    "albums":  list(),
		    "songs":   list()}

	# know where you are
	url = 'http://www.lyrics.net/'

	def investigate(self):

		# need this for interpretation
		import re

		# try not to repeat yourself
		try:

			last_artist = self.canvas.get_artists()[-20]
			caught_up = bool()

		# make sure you've actually started
		except IndexError:

			last_artist = None
			caught_up   = True

		# get the soup
		soup = self.communicate(self.url)

		# extract alphabet urls
		alphabet_urls = (self.url + re.match('^/artists/[A-Z0]$', link.get('href')).group(0) + '/99999' \
				 for link in soup.find_all('div', {'id': 'page-letter-search'})[0]      	\
				          if re.match('^/artists/[A-Z0]$', str(link.get('href'))))

		# extract artist tags
		artist_tags = (trace.strong.a 		  		     		  \
			       for alphabet_url in alphabet_urls 	     	 	  \
			       for trace in self.communicate(alphabet_url).find_all('tr') \
			       		 if trace.strong)

		# get artist data
		artist_data = ((artist_tag.text, self.url + artist_tag.get('href')) for artist_tag in artist_tags)

		# for each artist
		for artist_name, artist_url in artist_data: 
				
			print artist_name
			print

			if artist_name == last_artist: caught_up = True

			if not caught_up: continue

			self.multitask('artists', self.honor, artist_name, (artist_name, artist_url,))

	def honor(self, artist_name, artist_url):

		# get the soup
		artist_soup = self.communicate(artist_url)

		# add the artist to the canvas
		self.canvas.add_artist(artist_name)

		# get the album labels
		album_labels = artist_soup.find_all('h3', {'class': 'artist-album-label'})

		# for each album label
		for album_label in album_labels:

			# extract the data
			album_title = album_label.a.text
			album_url   = self.url + album_label.a.get('href')

			print '\t', album_title
			print

			self.multitask('albums', self.experience, album_title, (artist_name, artist_url, album_title, album_url,))

	def experience(self, artist_name, artist_url, album_title, album_url):

		# get the soup
		album_soup = self.communicate(album_url)

		# TODO handle the redirects
		if album_soup.find_all('body', {'id': 's4-page-homepage'}): 

			# keep track of the redirects
			with open('home_page_albums.txt', 'a') as f: f.write(artist_name.encode('utf-8') + ', ' + album_title.encode('utf-8') +'\n')

			return

		# add the album to the canvas
		self.canvas.add_album(artist_name, album_title)

		# extract the song data
		song_data = ((song_tag.a.text, self.url + song_tag.a.get('href'))  \
			     for song_tag in album_soup.find_all('strong') 	   \
			     		  if song_tag.a)

		# for each song
		for song_title, song_url in song_data:

			print '\t\t', song_title
			print

			self.multitask('songs', self.meditate, song_title, (album_title, song_title, song_url,))

	def meditate(self, album_title, song_title, song_url):

		# make some soup
		song_soup = self.communicate(song_url)

		# TODO handle redirects
		if song_soup.find_all('body', {'id': 's4-page-homepage'}): 
			
			# track redirects
			with open('home_page_songs.txt','a') as f: f.write(album_title.encode('utf-8') + ', ' + song_title.encode('utf-8') + '\n')

			return

		# sometimes there's nothing to meditate on
		try: 

			lyrics = song_soup.find_all('pre', {'id': 'lyric-body-text'})[0].text

			for line in lyrics.splitlines(): print '\t\t\t', line

			print

		except IndexError: return

		# add song to canvas
		self.canvas.add_song(album_title, song_title, lyrics)

if __name__ == '__main__':

	# setup redirect trackers
	with open('home_page_albums.txt', 'w') as f: f.write('')
	with open('home_page_songs.txt', 'w') as f:  f.write('')

	# start the investigation
	investigation = lyrics_net()
	investigation.investigate()
