#!/usr/bin/env python
#
# I should not like my writing to spare other people the trouble of thinking. 
# But, if possible, to stimulate someone to thoughts of their own.
#

# need this for pages
import requests

# need this to parse html
from bs4 import BeautifulSoup

# set url
url = 'http://www.lyrics.net'

# get page
page = requests.get(url)

# get soup
soup = BeautifulSoup(page.content, 'lxml')

# artist urls
urls = set()

# for each link
for link in soup.find_all('a'):

	# get the suburl
	suburl = link.get('href')

	# check for artist subpages
	if 'artists' in suburl:

		# hacky
		if '.php' in suburl or 'http' in suburl: continue

		# set artist url
		alphabet_url = url + suburl

		# get artist page
		alphabet_page = requests.get(alphabet_url)

		# get artist soup
		alphabet_soup = BeautifulSoup(alphabet_page.content, 'lxml')

		print
		print suburl
		print

		# get artist links
		for alphabet_link in alphabet_soup.find_all('a'):

	 		sublink = alphabet_link.get('href')

			if suburl in sublink:

				# set artist url
				sub_alphabet_url = url + suburl

				print
				print '\t', sub_alphabet_url
				print

				# get artist page
				sub_alphabet_page = requests.get(sub_alphabet_url)

				# get artist soup
				sub_alphabet_soup = BeautifulSoup(sub_alphabet_page.content, 'lxml')

				for sub_alphabet_link in sub_alphabet_soup.find_all('a'):

					if 'http' in str(sub_alphabet_link): continue

					if suburl in sub_alphabet_link.get('href'):

						if url + sub_alphabet_link.get('href') in urls: continue

						urls.add(url + sub_alphabet_link.get('href'))

						print '\t\t', url + sub_alphabet_link.get('href')

print urls
