#!/usr/bin/env python
#
# I should not like my writing to spare other people the trouble of thinking. 
# But, if possible, to stimulate someone to thoughts of their own.
#

class lyrics_site:

	caught_up = bool()

	def communicate(self, url):

		from bs4 import BeautifulSoup
		import requests

		# never stop trying
		while True:

			# make some soup
			try:

				page = requests.get(url)
				soup = BeautifulSoup(page.content)

				return soup

			# give communication a chance
			except requests.exceptions.ConnectionError: pass

class lyrics_net(lyrics_site): 

	# get some inspiration
	url = 'http://www.lyrics.net/'

	# set the canvas
	import MySQLdb

	canvas = MySQLdb.connect('localhost', 'root')
	brush  = canvas.cursor()

	try: 

		brush.execute("create database lyrics_net")
		canvas.close()

	except: canvas.close()

	# sketch the outline
	canvas = MySQLdb.connect('localhost', 'root', db ='lyrics_net')
	brush  = canvas.cursor()

	brush.execute("""create table if not exists artists (
								  
				 name varchar(255) not null, 	  
								  
				 primary key (name) 		  
								  
				 )""")

	brush.execute("""create table if not exists albums ( 		
										
				 artist_name varchar(255) not null,  		
										
				 title varchar(255) not null, 			
										
				 primary key (title), 				
				 foreign key (artist_name) references artists (name) 
										
				 )""")

	brush.execute("""create table if not exists songs ( 	    	       
								    	       
				 id int unsigned not null auto_increment, 	       
									       
				 album_title varchar(255) not null, 	    	       
									       
				 title varchar(255) not null, 	    	       
									       
				 lyrics text, 			    	       
									       
				 primary key (id), 			    	       
				 foreign key (album_title) references albums (title) 
									       
				 )""")

	def investigate(self):

		# need this to understand the text
		import re

		# talk to the text
		soup = self.communicate(self.url)

		# get the priests
		alphabet_urls = (self.url + re.match('^/artists/[A-Z0]$', link.get('href')).group(0) + '/99999' \
				 for link in soup.find_all('div', {'id': 'page-letter-search'})[0] 		\
				          if re.match('^/artists/[A-Z0]$', str(link.get('href'))))

		artist_tags = (trace.find_all('strong')[0].find_all('a')[0] 		  \
			       for alphabet_url in alphabet_urls 	    		  \
			       for trace in self.communicate(alphabet_url).find_all('tr') \
			       		 if trace.find_all('strong'))

		# don't repeat yourself
		self.brush.execute("select name from artists order by name desc limit 1")

		last_artist_name = self.brush.fetchone()[0]

		artist_data = ((artist_tag.text, self.url + artist_tag.get('href')) for artist_tag in artist_tags)

		# talk to all the priests
		for artist_name, artist_url in artist_data: 
			
			# check if you're caught up
			if artist_name != last_artist_name and not self.caught_up: 
				
				print artist_name
				continue

			self.caught_up = True
	
			# honor the priest
			self.honor(artist_name, artist_url)

	def honor(self, artist_name, artist_url):

		# don't forget the priest
		print
		print artist_name
		print

		self.brush.execute("""insert into artists (name)
				      values (%s)
				      on duplicate key update
				      name = name""",
				      [artist_name])

		self.canvas.commit()

		# attend the masses
		soup = self.communicate(artist_url)

		# conduct their masses
		for album_label in soup.find_all('h3', {'class': 'artist-album-label'}): 
			
			self.admire(artist_name, self.url + album_label.find_all('a')[0].get('href'), album_label.find_all('a')[0].text)

	def admire(self, artist_name, album_url, album_title):

		# don't forget the mass
		print '\t', album_url
		print '\t', album_title
		print

		self.brush.execute("""insert into albums (artist_name, title)
				      values (%s, %s)
				      on duplicate key update
				      artist_name = artist_name, title = title""",
				      [artist_name, album_title])

		self.canvas.commit()

		soup = self.communicate(album_url)

		# find their prayers
		song_data = ((self.url + song_tag.find_all('a')[0].get('href'), song_tag.find_all('a')[0].text) \
			     for song_tag in soup.find_all('strong') 						\
			     		  if song_tag.find_all('a'))

		for song_url, song_title in song_data: self.experience(album_title, song_url, song_title)

	def experience(self, album_title, song_url, song_title):

		# please kneel
		print '\t\t', song_url
		print '\t\t', song_title
		print

		soup = self.communicate(song_url)

		try: lyrics = soup.find_all('pre', {'id': 'lyric-body-text'})[0].text

		except IndexError: return

		for line in lyrics.splitlines():

			print '\t\t\t', line

		print

		self.brush.execute("""insert into songs (album_title, title, lyrics)
				      values (%s, %s, %s)
				      on duplicate key update
				      album_title = album_title, title = title, lyrics = lyrics""",
				      [album_title, song_title, lyrics])

		self.canvas.commit()

investigation = lyrics_net()

investigation.investigate()
